{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "PTAP_tutorial_keras.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kirarenctaon/PTAP/blob/master/PTAP_tutorial_keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "BXHVybW_aqoN"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "from matplotlib.pyplot import cm\n",
        "\n",
        "import keras\n",
        "from keras import optimizers\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Input, Dense, Activation, Flatten, Dropout, Reshape, GlobalAveragePooling1D\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "\n",
        "from sklearn.preprocessing import normalize"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrmExzXQaqoP"
      },
      "source": [
        "def readucr(filename):\n",
        "    data = np.loadtxt(filename)\n",
        "    Y = data[:,0]\n",
        "    X = data[:,1:]\n",
        "    return X, Y"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8AIcUXKuaqoP"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GAWDPE3aazDV",
        "outputId": "fd36f02e-7749-4975-c734-8a64a6b11d08"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIiSOW7RaqoQ"
      },
      "source": [
        "path = '/content/drive/MyDrive/PTAP_Tutorial/data/'\n",
        "x_train, y_train = readucr(path+'StarLightCurves_TRAIN.txt')\n",
        "x_test, y_test = readucr(path+'StarLightCurves_TEST.txt')\n",
        "nb_classes = len(np.unique(y_test))\n",
        "batch_size = min(x_train.shape[0]/10, 16)\n",
        "\n",
        "y_train = (y_train - y_train.min())/(y_train.max()-y_train.min())*(nb_classes-1)\n",
        "y_test = (y_test - y_test.min())/(y_test.max()-y_test.min())*(nb_classes-1)\n",
        "\n",
        "x_train_mean = x_train.mean()\n",
        "x_train_std = x_train.std()\n",
        "x_train = (x_train - x_train_mean)/(x_train_std)\n",
        "x_test = (x_test - x_train_mean)/(x_train_std)\n",
        "\n",
        "trainX = x_train[:, np.newaxis, :, np.newaxis]\n",
        "testX = x_test[:, np.newaxis, :, np.newaxis]\n",
        "\n",
        "trainY = np_utils.to_categorical(y_train, nb_classes)\n",
        "testY = np_utils.to_categorical(y_test, nb_classes)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4Ltec4faqoQ"
      },
      "source": [
        "## Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSfB8j7yaqoQ"
      },
      "source": [
        "conv1_channel, conv2_channel, conv3_channel = 32, 64, 128\n",
        "\n",
        "conv1_size, conv2_size, conv3_size = 15, 11, 7\n",
        "conv1_pad, conv2_pad, conv3_pad = int((conv1_size -1) /2),int((conv2_size -1) /2),int((conv3_size -1) /2)\n",
        "conv1_stride, conv2_stride, conv3_stride = 2, 1, 1\n",
        "\n",
        "pool1_size, pool2_size, pool3_size = 8, 4, 4\n",
        "pool1_pad, pool2_pad, pool3_pad = 0, 0, 0\n",
        "pool1_stride, pool2_stride, pool3_stride = 4, 2, 2"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "RFxK1LqEaqoR"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "## Layer 1\n",
        "model.add(keras.layers.Conv2D(input_shape =(trainX.shape[1:]), \n",
        "                              filters=conv1_channel, kernel_size=conv1_size, strides=conv1_stride, padding='same'))\n",
        "model.add(keras.layers.BatchNormalization())\n",
        "model.add(keras.layers.Activation('relu'))\n",
        "model.add(keras.layers.MaxPool2D(pool_size =pool1_size, strides=pool1_stride, padding='same', name='pool1'))\n",
        "                          \n",
        "## Layer 2          \n",
        "model.add(keras.layers.Conv2D(filters=conv2_channel, kernel_size=conv2_size, strides=conv2_stride, padding='same'))\n",
        "model.add(keras.layers.BatchNormalization())\n",
        "model.add(keras.layers.Activation('relu'))\n",
        "model.add(keras.layers.MaxPool2D(pool_size =pool2_size, strides=pool2_stride, padding='same', name='pool2'))\n",
        " \n",
        "## Layer 3          \n",
        "model.add(keras.layers.Conv2D(filters=conv3_channel, kernel_size=conv3_size, strides=conv3_stride, padding='same'))\n",
        "model.add(keras.layers.BatchNormalization())\n",
        "model.add(keras.layers.Activation('relu'))\n",
        "model.add(keras.layers.MaxPool2D(pool_size =pool3_size, strides=pool3_stride, padding='same', name='pool3'))\n",
        "\n",
        "model.add(keras.layers.Flatten())\n",
        "model.add(keras.layers.Dense(nb_classes, activation='softmax'))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "6EjRQ6D6aqoS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8df3c6b3-a005-41b5-cf22-7dcf8d30b275"
      },
      "source": [
        "adam = optimizers.Adam(lr = 0.001)\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer = adam, metrics = ['accuracy'])\n",
        "\n",
        "history = model.fit(trainX, trainY, batch_size = 128, validation_split = 0.2, \n",
        "                    epochs = 10, verbose = 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "7/7 [==============================] - 25s 1s/step - loss: 0.9325 - accuracy: 0.6744 - val_loss: 1.0611 - val_accuracy: 0.8850\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.2925 - accuracy: 0.8867 - val_loss: 1.0245 - val_accuracy: 0.9000\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.2665 - accuracy: 0.8937 - val_loss: 1.0259 - val_accuracy: 0.7500\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 8s 1s/step - loss: 0.2204 - accuracy: 0.9054 - val_loss: 1.0388 - val_accuracy: 0.5400\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTDxlKvhaqoT"
      },
      "source": [
        "# Extract TAP (Temporallly Activated Patterns) using receptive field "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4koVOzBiaqoT"
      },
      "source": [
        "### Calculate Receptive Field for Keras "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8VTtQVeaqoU"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gqP2SGraqoU"
      },
      "source": [
        "def nextlen(l, size, pad, stride):\n",
        "    return int((l+2*pad-size+stride)/stride ) \n",
        "\n",
        "input_len = trainX.shape[2]\n",
        "l1_conv_len = nextlen(input_len, conv1_size, conv1_pad, conv1_stride)\n",
        "l1_pool_len = nextlen(l1_conv_len, pool1_size, pool1_pad, pool1_stride) +1\n",
        "l2_conv_len = nextlen(l1_pool_len, conv2_size, conv2_pad, conv2_stride)\n",
        "l2_pool_len = nextlen(l2_conv_len, pool2_size, pool2_pad, pool2_stride) +1\n",
        "l3_conv_len = nextlen(l2_pool_len, conv3_size, conv3_pad, conv3_stride)\n",
        "l3_pool_len = nextlen(l3_conv_len, pool3_size, pool3_pad, pool3_stride) +1\n",
        "print(l1_conv_len,l1_pool_len,l2_conv_len,l2_pool_len,l3_conv_len,l3_pool_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdSl10UVaqoV"
      },
      "source": [
        "Receptive_Field_index3 = []\n",
        "for node in range(l3_pool_len):\n",
        "    l3_conv_start = node*pool3_stride - pool3_pad\n",
        "    l3_conv_end = node*pool3_stride - pool3_pad + pool3_size - 1\n",
        "    l2_result_start = l3_conv_start*conv3_stride - conv3_pad\n",
        "    l2_result_end = l3_conv_end*conv3_stride - conv3_pad + conv3_size -1    \n",
        "    l2_conv_start = l2_result_start*pool3_stride - pool2_pad\n",
        "    l2_conv_end = l2_result_end*pool2_stride - pool2_pad + pool2_size - 1\n",
        "    l1_result_start = l2_conv_start*conv2_stride - conv2_pad\n",
        "    l1_result_end = l2_conv_end*conv2_stride - conv2_pad + conv2_size -1\n",
        "    l1_conv_start = l1_result_start*pool1_stride - pool1_pad\n",
        "    l1_conv_end = l1_result_end*pool1_stride - pool1_pad + pool1_size - 1\n",
        "    input_start = l1_conv_start*conv1_stride - conv1_pad\n",
        "    input_end = l1_conv_end*conv1_stride - conv1_pad + conv1_size -1\n",
        "    Receptive_Field_index3.append(np.arange(input_start,input_end+1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyctPbYDaqoV"
      },
      "source": [
        "### Load Intermediate layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRqUg4dyaqoV"
      },
      "source": [
        "layer_name = 'pool3'\n",
        "intermediate_layer_model = Model(inputs=model.input,\n",
        "                                 outputs=model.get_layer(layer_name).output)\n",
        "intermediate_output = intermediate_layer_model.predict(trainX)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nO4f-8w9aqoV"
      },
      "source": [
        "### Get Highly Activated Nodes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hqZ9NmRaqoW"
      },
      "source": [
        "layer_name = 'pool3'\n",
        "intermediate_layer_model = Model(inputs=model.input,\n",
        "                                 outputs=model.get_layer(layer_name).output)\n",
        "intermediate_output = intermediate_layer_model.predict(trainX)\n",
        "\n",
        "percent = 5  ### top 5%\n",
        "\n",
        "### Get Highly \n",
        "threshold = np.percentile(intermediate_output,100-percent,[0,1,2])\n",
        "threshold_bool = (intermediate_output > threshold).squeeze()     \n",
        "\n",
        "pattern_length = np.max([len(x) for x in Receptive_Field_index3])\n",
        "\n",
        "reindex_threshold_bool=[]\n",
        "for data_idx in range(len(trainX)):\n",
        "    for output_c in range(conv3_channel):\n",
        "        if len([x for x in threshold_bool[data_idx,:,output_c].flatten() if x]):\n",
        "            index = []\n",
        "            for idx in [i for i,x in enumerate(threshold_bool[data_idx,:,output_c].flatten()) if x]:    \n",
        "                reindex_threshold_bool.append([data_idx,output_c,idx])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtW4fjF8aqoW"
      },
      "source": [
        "### Save Pattern Information"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NkErwgSaqoW"
      },
      "source": [
        "pattern_idx_df = pd.DataFrame(reindex_threshold_bool,columns=[\"data_idx\",\"output_channel\",\"pattern_xs\"])\n",
        "groups = pattern_idx_df.groupby([\"data_idx\",\"pattern_xs\"])#[\"output_channel\"].apply(list)\n",
        "pattern_repetitive_idx_df = groups[\"output_channel\"].apply(list).reset_index(name='output_channel')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpfeqzZhaqoW"
      },
      "source": [
        "TAP=[]\n",
        "pattern_id=0\n",
        "\n",
        "data_idx = pattern_repetitive_idx_df.loc[:,\"data_idx\"].values.tolist()\n",
        "output_channel = pattern_repetitive_idx_df.loc[:,\"output_channel\"].values.tolist()\n",
        "pattern_xs = pattern_repetitive_idx_df.loc[:,\"pattern_xs\"].values.tolist()\n",
        "\n",
        "for d_idx, output_c, p_xs in zip(data_idx, output_channel, pattern_xs):\n",
        "    for input_c in range(trainX.shape[3]):\n",
        "        if (Receptive_Field_index3[p_xs][0] >= 0) and (Receptive_Field_index3[p_xs][-1] < trainX.shape[2]) :\n",
        "            pattern_dict={}\n",
        "            pattern_dict[\"pattern_id\"]= pattern_id\n",
        "            pattern_dict[\"data_idx\"] = d_idx\n",
        "            pattern_dict[\"output_channel\"] = output_c\n",
        "            pattern_dict[\"input_channel\"] = input_c\n",
        "            pattern_dict[\"pattern_xs\"]= Receptive_Field_index3[p_xs]\n",
        "            pattern_dict[\"pattern_ys\"] = trainX[d_idx, 0, Receptive_Field_index3[p_xs], input_c]\n",
        "            pattern_dict[\"features\"] = intermediate_output[d_idx, 0, p_xs, :]\n",
        "            pattern_dict[\"activations\"] = threshold_bool[d_idx, p_xs, :]\n",
        "\n",
        "            TAP.append(pattern_dict)\n",
        "            pattern_id += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z98tvMMpaqoW"
      },
      "source": [
        "# np.save(\"activated_subsequences_StarLightCurves.npy\", TAP)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTlMn1xFaqoX"
      },
      "source": [
        "# Select Prototype"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Un5opzFjaqoX"
      },
      "source": [
        "def select_greedy_protos(K, m):\n",
        "\n",
        "    ''' selected: an array of selected prototypes '''\n",
        "    ''' obj_list: a list of the objective values '''\n",
        "\n",
        "    n = np.shape(K)[0]\n",
        "    selected = np.array([], dtype=int)\n",
        "    obj_list = []\n",
        "    nsk = 0\n",
        "\n",
        "    colsum = 2/n*np.sum(K, axis=0)\n",
        "\n",
        "    for i in range(m):\n",
        "        argmax = -1\n",
        "        candidates = np.setdiff1d(range(n), selected)\n",
        "        vec1 = colsum[candidates]\n",
        "        lenS = len(selected)\n",
        "\n",
        "        if lenS > 0:\n",
        "            temp = K[selected, :][:, candidates]\n",
        "            vec2 = np.sum(temp, axis=0) *2 + np.diagonal(K)[candidates]\n",
        "            vec2 = vec2/(lenS + 1)\n",
        "            vec3 = vec1 - vec2\n",
        "        else:\n",
        "            vec3 = vec1 - (np.abs(np.diagonal(K)[candidates]))\n",
        "\n",
        "        ''' vec3: {J(selected U {new})-J(selected)}*(lenS + 1) '''\n",
        "        ''' increase of the objective value'''\n",
        "        max_idx = np.argmax(vec3)\n",
        "\n",
        "        if lenS > 0:\n",
        "            ''' j: J(selected U {new})'''\n",
        "            sk = np.sum(K[selected, :][:, selected])\n",
        "            j = vec3[max_idx]/(lenS+1) - nsk/(lenS*(lenS+1)) + (1/(lenS**2)-1/((lenS+1)**2))*sk\n",
        "            obj_list.append(j)\n",
        "        else:\n",
        "            obj_list.append(vec3[max_idx])\n",
        "\n",
        "        argmax = candidates[max_idx]\n",
        "        selected = np.append(selected, argmax)\n",
        "\n",
        "        ''' nsk: (2/n)*\\sum{k([n],S)} '''\n",
        "        nsk += vec1[max_idx]\n",
        "\n",
        "    return selected, obj_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ohGly2xaqoX"
      },
      "source": [
        "data_indices = np.array([x['data_idx'] for x in TAP])\n",
        "subsequences = np.array([x['pattern_ys'] for x in TAP])\n",
        "features = np.array([x['features'] for x in TAP])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGD4Z6o6aqoX"
      },
      "source": [
        "** You need enough CPU memory for here. Some datasets require more than 1TB CPU memory. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BB4065_5aqoX"
      },
      "source": [
        "%%time\n",
        "\n",
        "powers = 20\n",
        "pat = np.array(features)\n",
        "pat = pat/(np.linalg.norm(pat, axis=1).reshape(-1,1))\n",
        "pat = normalize(pat, norm='l2')\n",
        "\n",
        "gram_kernel = np.power(np.inner(pat, pat), powers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYfynYCJaqoY"
      },
      "source": [
        "# Gram kernel\n",
        "m= 8  ## the number of prototype\n",
        "selected, obj_list= select_greedy_protos(gram_kernel, m)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uU-IDipWaqoY"
      },
      "source": [
        "### Visualzation of all prototypes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQVRAVODaqoY"
      },
      "source": [
        "color = cm.rainbow(np.linspace(0,1,m))[::-1]\n",
        "classified = np.argmax(gram_kernel[:, selected[:m]], axis=1)\n",
        "yrange=(-3.5,3.5)\n",
        "protos = subsequences[selected[:m]]\n",
        "\n",
        "row = int((m-1)/16)+1\n",
        "column = 16\n",
        "# fig = plt.figure(figsize=(25,3*row))\n",
        "fig = plt.figure(figsize=(40,row*2.5))\n",
        "gs = gridspec.GridSpec(row,column)\n",
        "gs.update(wspace=0, hspace=0)\n",
        "\n",
        "for n in range(m):\n",
        "    group_idx = [i for i,x in enumerate(classified) if x == n]\n",
        "    members = subsequences[classified==n]\n",
        "    proto_std = members.std(axis=0)\n",
        "    proto_mean = members.mean(axis=0)\n",
        "    ax = plt.subplot(gs[n])\n",
        "                     \n",
        "    ax.plot(proto_mean, color='black',alpha=0.6)\n",
        "    ax.plot(protos[n], color =color[n],alpha=1,linewidth=5)\n",
        "\n",
        "    ax.set_ylim(yrange)\n",
        "    \n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "    plt.setp(ax.spines.values(), linewidth=2)\n",
        "    \n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9VTEUNQaqoY"
      },
      "source": [
        "### Visualzation of a specific prototype"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLU7-qCEaqoY"
      },
      "source": [
        "proto_idx = 2\n",
        "display_n = 6\n",
        "\n",
        "group_idx = [i for i,x in enumerate(classified) if x == proto_idx]\n",
        "members = subsequences[classified==proto_idx]\n",
        "proto_std = members.std(axis=0)\n",
        "proto_mean = members.mean(axis=0)\n",
        "\n",
        "plt.figure(figsize=(2,2))\n",
        "plt.plot(protos[proto_idx], color =color[proto_idx],alpha=1,linewidth=5)\n",
        "plt.ylim(-3.5,3.5)\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "plt.title(\"Prototype {}\".format(proto_idx))\n",
        "plt.show()\n",
        "\n",
        "fig = plt.figure(figsize=(1.7*display_n, 2))\n",
        "gs = gridspec.GridSpec(1,display_n)\n",
        "gs.update(wspace=0, hspace=0)\n",
        "\n",
        "indices =  np.random.choice(len(members), display_n, replace=False)\n",
        "for t, member in enumerate(members[indices]):\n",
        "    ax = plt.subplot(gs[t])\n",
        "    ax.plot(member, linewidth=2.5, color='black')\n",
        "\n",
        "    ax.set_ylim(yrange)\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "    plt.setp(ax.spines.values(), linewidth=2)\n",
        "    \n",
        "plt.suptitle(\"PTAPs in Prototype {}\".format(proto_idx), y=1.1, fontsize=18)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPCFTWagaqoZ"
      },
      "source": [
        "### Visualzation with input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vj9qk0n3aqoZ"
      },
      "source": [
        "data_indices = np.array([x['data_idx'] for x in TAP])\n",
        "subsequences = np.array([x['pattern_ys'] for x in TAP])\n",
        "subseq_x = np.array([x['pattern_xs'] for x in TAP])\n",
        "features = np.array([x['features'] for x in TAP])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzSvIS1-aqoZ"
      },
      "source": [
        "### Random Choose Patterns & Romove Overap"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHX-J3wDaqoZ"
      },
      "source": [
        "tar_class = 2\n",
        "tar_set = np.where(np.argmax(trainY, axis=1)==tar_class)[0]\n",
        "\n",
        "idx = np.random.choice(tar_set, 1)[0]\n",
        "\n",
        "pattern_list = np.where(data_indices==idx)[0]\n",
        "pattern_list = pattern_list[np.argsort(-np.max(gram_kernel[pattern_list, :], axis=1))]\n",
        "\n",
        "pattern_list2 = []\n",
        "for i, p in enumerate(pattern_list):\n",
        "    if i==0:\n",
        "        pattern_list2.append(p)\n",
        "    else:\n",
        "        add = True\n",
        "        for p2 in pattern_list2:\n",
        "            if np.abs(subseq_x[p][0] - subseq_x[p2][0])<150:\n",
        "                add = False\n",
        "                break\n",
        "        if add:\n",
        "            pattern_list2.append(p)\n",
        "\n",
        "fig = plt.figure(figsize=(8,3))\n",
        "\n",
        "plt.title(\"Data {} | Class {}\".format(idx, tar_class),fontsize=15)\n",
        "plt.plot(trainX[idx].squeeze(), c='black')\n",
        "\n",
        "# p_idx = pattern_list[0]\n",
        "corres_p_list = []\n",
        "for i, p_idx in  enumerate(pattern_list2):\n",
        "    proto_idx = classified[p_idx]\n",
        "    corres_p_list.append(proto_idx)\n",
        "    \n",
        "    members = subsequences[classified==proto_idx]\n",
        "    proto_std = members.std(axis=0)*1.5\n",
        "    proto_mean = members.mean(axis=0)\n",
        "    \n",
        "    plt.fill_between(subseq_x[p_idx, :], proto_mean-proto_std, proto_mean+proto_std, color=color[proto_idx], alpha=0.2)\n",
        "    plt.plot(subseq_x[p_idx, :], protos[proto_idx], c=color[proto_idx], linewidth=5, alpha=0.75)\n",
        "\n",
        "plt.xticks([])\n",
        "plt.ylim(-3,3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBp42KoRaqoa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgaJko4saqoa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}